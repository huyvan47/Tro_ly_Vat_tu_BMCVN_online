import numpy as np
import re
from openai import OpenAI

# ==============================
#       CONFIG
# ==============================

FT_MODEL = "ft:gpt-4o-mini-2024-07-18:personal::CdBoxNIT"   # ƒë·ªïi th√†nh model c·ªßa b·∫°n

MIN_SCORE_MAIN = 0.60       # T·ªëi thi·ªÉu ƒë·ªÉ d√πng l√†m context
MIN_SCORE_SUGGEST = 0.50    # T·ªëi thi·ªÉu ƒë·ªÉ d√πng l√†m g·ª£i √Ω
MAX_SUGGEST = 5             # G·ª£i √Ω t·ªëi ƒëa 5 c√¢u

client = OpenAI(api_key="...")

# ==============================
#       LOAD DATA
# ==============================

data = np.load("tong-hop-data-phong-vat-tu-fix-24-11.npz", allow_pickle=True)
EMBS = data["embeddings"]      # (N, d)
QUESTIONS = data["questions"]  # (N,)
ANSWERS = data["answers"]      # (N,)

# ==============================
#       EMBEDDING FUNCTION
# ==============================

def embed_query(text: str):
    resp = client.embeddings.create(
        model="text-embedding-3-small",
        input=[text],
    )
    v = np.array(resp.data[0].embedding, dtype=np.float32)
    v = v / (np.linalg.norm(v) + 1e-8)
    return v




def extract_img_keys(text: str):
    """
    T√¨m t·∫•t c·∫£ (IMG_KEY: xxx) trong text v√† tr·∫£ v·ªÅ list key ['xxx', ...]
    """
    return re.findall(r'\(IMG_KEY:\s*([^)]+)\)', text)

def remove_img_keys(text: str):
    """
    Xo√° s·∫°ch ph·∫ßn '(IMG_KEY: ...)' kh·ªèi text ƒë·ªÉ context g·ª≠i v√†o LLM ƒë∆∞·ª£c s·∫°ch s·∫Ω.
    """
    return re.sub(r'-?\s*\(IMG_KEY:[^)]+\)\s*', '', text).strip()

def extract_codes_from_query(text: str):
    """
    T√¨m c√°c c·ª•m gi·ªëng m√£ v·∫≠t t∆∞: ch·ªØ + s·ªë + g·∫°ch, ho·∫∑c s·ªë + g·∫°ch (vd: 'cha1000-20', '1000-20', 'cha240-asmil')
    B·∫°n c√≥ th·ªÉ ch·ªânh regex cho ph√π h·ª£p d·ªØ li·ªáu th·ª±c t·∫ø.
    """
    # V√≠ d·ª• ƒë∆°n gi·∫£n: t·ª´ ch·ª©a c·∫£ s·ªë v√† d·∫•u g·∫°ch ngang
    return re.findall(r'\b[\w]*\d[\w-]*-\d[\w-]*\b', text)

# ==============================
#     NORMALIZE QUERY
# ==============================

def normalize_query(q: str):
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0,
        messages=[
            {
                "role": "system",
                "content": """
B·∫°n l√† Query Normalizer.
Nhi·ªám v·ª•:
- S·ª≠a l·ªói ch√≠nh t·∫£ KH√îNG ƒê∆Ø·ª¢C thay ƒë·ªïi b·∫•t k·ª≥ k√Ω t·ª± n√†o b√™n trong c√°c chu·ªói c√≥ ch·ª©a s·ªë v√† d·∫•u g·∫°ch ngang ch·∫°y li·ªÅn nhau (v√≠ d·ª•: "cha240-asmil", "cha1000-02logo", "450-02", "cha240-04").
- Khi th·∫•y m·ªôt c·ª•m gi·ªëng m√£ (bao g·ªìm ch·ªØ c√°i + s·ªë + d·∫•u g·∫°ch ngang, ho·∫∑c s·ªë + g·∫°ch ngang), ph·∫£i gi·ªØ NGUY√äN Y H·ªÜT, kh√¥ng s·ª≠a ch√≠nh t·∫£, kh√¥ng th√™m/b·ªõt kho·∫£ng tr·∫Øng.
- D·ª±a t·ªëi ƒëa v√†o NG·ªÆ C·∫¢NH ƒë·ªÉ tr·∫£ l·ªùi.
- Ch·ªâ s·ª≠a l·ªói ch√≠nh t·∫£ + chu·∫©n ho√° vƒÉn b·∫£n h·ªèi.
- C√≥ th·ªÉ di·ªÖn gi·∫£i l·∫°i cho d·ªÖ hi·ªÉu, nh∆∞ng kh√¥ng ƒë∆∞·ª£c th√™m n·ªôi dung kh√¥ng c√≥ trong ng·ªØ c·∫£nh.
                """
            },
            {"role": "user", "content": q}
        ],
    )
    return resp.choices[0].message.content.strip()

# ==============================
#        SEARCH ENGINE
# ==============================

def search(query: str, top_k: int = 10):
    norm_query = normalize_query(query)
    print("norm_query:", norm_query)

    vq = embed_query(norm_query)
    sims = EMBS @ vq         # cosine similarity

    idx = np.argsort(sims)[::-1][:top_k]

    results = []
    for i in idx:
        results.append({
            "question": str(QUESTIONS[i]),
            "answer": str(ANSWERS[i]),
            "score": float(sims[i]),
        })

    return results

# ==============================
#   CALL FINE-TUNE FOR ANSWER
# ==============================

def call_finetune_with_context(user_query: str, context: str, suggestions_text: str):
    print("user_query: ", user_query)
    print("context: ", context)
    # print("suggestions_text: ", suggestions_text)

    system_prompt = (
        "B·∫°n l√† Tr·ª£ l√Ω V·∫≠t t∆∞ BMCVN. "
        "B·∫°n tr·∫£ l·ªùi d·ª±a tr√™n t√†i li·ªáu n·ªôi b·ªô ƒë∆∞·ª£c cung c·∫•p (NG·ªÆ C·∫¢NH). "
        "Gi·ªçng chuy√™n nghi·ªáp, r√µ r√†ng, c√≥ bullet khi c·∫ßn. "
        "TUY·ªÜT ƒê·ªêI kh√¥ng b·ªãa th√¥ng tin ngo√†i nh·ªØng g√¨ c√≥ trong NG·ªÆ C·∫¢NH. "
        "N·∫øu d·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c, h√£y n√≥i r√µ 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c' "
        "v√† g·ª£i √Ω ng∆∞·ªùi d√πng cung c·∫•p th√™m th√¥ng tin."
    )

    user_prompt = f"""
NG·ªÆ C·∫¢NH (nhi·ªÅu ƒëo·∫°n t√†i li·ªáu n·ªôi b·ªô, c√≥ th·ªÉ kh√¥ng ƒë·∫ßy ƒë·ªß):
\"\"\"{context}\"\"\"

C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG:
\"\"\"{user_query}\"\"\"

Y√äU C·∫¶U TR·∫¢ L·ªúI:
- D√πng T·ªêI ƒêA th√¥ng tin trong NG·ªÆ C·∫¢NH ƒë·ªÉ tr·∫£ l·ªùi, c√≥ th·ªÉ k·∫øt h·ª£p nhi·ªÅu ƒëo·∫°n kh√°c nhau.
- Kh√¥ng ƒë∆∞·ª£c ƒë∆∞a th√¥ng tin kh√¥ng xu·∫•t hi·ªán trong NG·ªÆ C·∫¢NH.
- C√≥ th·ªÉ suy lu·∫≠n, so s√°nh, t·ªïng h·ª£p t·ª´ nhi·ªÅu ƒëo·∫°n, nh∆∞ng kh√¥ng ƒë∆∞·ª£c t·ª± b·ªãa s·ªë li·ªáu/quy ƒë·ªãnh m·ªõi.
- Tr√¨nh b√†y ng·∫Øn g·ªçn, r√µ r√†ng, ∆∞u ti√™n bullet cho c√°c b∆∞·ªõc/th·ªß t·ª•c.
- N·∫øu NG·ªÆ C·∫¢NH kh√¥ng ƒë·ªß, h√£y n√≥i r√µ 'Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c' v√† gi·∫£i th√≠ch thi·∫øu g√¨.

DANH S√ÅCH C√ÇU H·ªéI G·ª¢I √ù (CHO PH·∫¶N G·ª¢I √ù CU·ªêI C√ôNG, N·∫æU C·∫¶N):
{suggestions_text}

SAU KHI TR·∫¢ L·ªúI:
- (Tu·ª≥ ch·ªçn) C√≥ th·ªÉ g·ª£i √Ω 1‚Äì3 c√¢u h·ªèi ti·∫øp theo d·ª±a tr√™n danh s√°ch tr√™n, di·ªÖn ƒë·∫°t l·∫°i cho t·ª± nhi√™n h∆°n.
- C√°c c√¢u g·ª£i √Ω n√™n ƒë·∫∑t trong ngo·∫∑c k√©p ƒë·ªÉ user d·ªÖ copy, v√≠ d·ª•: "Anh/ch·ªã c√≥ th·ªÉ h·ªèi th√™m v·ªÅ quy tr√¨nh ƒë·∫∑t v·∫≠t t∆∞ d·ª± ph√≤ng cha240-asmil?".
""".strip()

    resp = client.chat.completions.create(
        model="gpt-4o-mini",   # ho·∫∑c FT_MODEL n·∫øu b·∫°n mu·ªën d√πng model fine-tune
        temperature=0.0,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
    )

    return resp.choices[0].message.content.strip()


# ==============================
#   MAIN PIPELINE (FULL FLOW)
# ==============================

def answer_with_suggestions(user_query: str):
    # C√≥ th·ªÉ normalize ƒë·ªÉ b·∫Øt m√£ t·ªët h∆°n
    norm_query = normalize_query(user_query)
    hits = search(user_query, top_k=20)

    if not hits:
        return {
            "text": "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p.",
            "img_keys": [],
        }

    filtered_for_main = [h for h in hits if h["score"] >= MIN_SCORE_MAIN]

    if not filtered_for_main:
        suggestions_text = "\n".join(
            f"- {h['question']} (score={h['score']:.2f})"
            for h in hits
        )

        text = (
            "üîç Kh√¥ng c√≥ t√†i li·ªáu n√†o ƒë·ªß ƒë·ªô t∆∞∆°ng ƒë·ªìng ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c c√¢u h·ªèi n√†y.\n"
            "Tuy nhi√™n, b·∫°n c√≥ th·ªÉ tham kh·∫£o c√°c ch·ªß ƒë·ªÅ g·∫ßn gi·ªëng d∆∞·ªõi ƒë√¢y:\n\n"
            f"{suggestions_text}\n\n"
            "üëâ B·∫°n c√≥ th·ªÉ ch·ªçn 1 c√¢u b√™n tr√™n ho·∫∑c h·ªèi r√µ h∆°n ƒë·ªÉ m√¨nh t√¨m ƒë√∫ng t√†i li·ªáu."
        )
        return {
            "text": text,
            "img_keys": [],
        }

    # ==============================
    #   X√ÅC ƒê·ªäNH DOC CH√çNH (PRIMARY)
    # ==============================

    code_candidates = extract_codes_from_query(norm_query.lower())
    primary_doc = None

    if code_candidates:
        # ∆∞u ti√™n code ƒë·∫ßu ti√™n
        target_code = code_candidates[0]
        for h in filtered_for_main:
            if (target_code in h["question"].lower()) or (target_code in h["answer"].lower()):
                primary_doc = h
                break

    # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c b·∫±ng m√£ ‚Üí d√πng doc c√≥ score cao nh·∫•t
    if primary_doc is None:
        primary_doc = filtered_for_main[0]

    # ƒê·∫£m b·∫£o primary_doc ƒë·ª©ng ƒë·∫ßu danh s√°ch context
    MAX_CONTEXT_DOCS = 5
    main_context_hits = []

    # th√™m primary_doc tr∆∞·ªõc
    main_context_hits.append(primary_doc)

    # th√™m c√°c doc kh√°c (kh√¥ng tr√πng) cho ƒë·ªß MAX_CONTEXT_DOCS
    for h in filtered_for_main:
        if h is primary_doc:
            continue
        if len(main_context_hits) >= MAX_CONTEXT_DOCS:
            break
        main_context_hits.append(h)

    # ==============================
    #   T·∫†O CONTEXT + IMG_KEY
    # ==============================

    context_blocks = []

    # 1) IMG_KEY ch·ªâ l·∫•y t·ª´ primary_doc
    raw_answer_primary = primary_doc["answer"]
    img_keys_primary = extract_img_keys(raw_answer_primary)

    # 2) Context: t·ª´ nhi·ªÅu DOC, nh∆∞ng ƒë√£ clean IMG_KEY
    for i, h in enumerate(main_context_hits, start=1):
        raw_answer = h["answer"]
        cleaned_answer = remove_img_keys(raw_answer)

        block = (
            f"[DOC {i}]\n"
            f"C√ÇU H·ªéI M·∫™U: {h['question']}\n"
            f"C√ÇU TR·∫¢ L·ªúI / T√ÄI LI·ªÜU LI√äN QUAN:\n{cleaned_answer}"
        )
        context_blocks.append(block)

    context = "\n\n------------------------------\n\n".join(context_blocks)

    # ==============================
    #   G·ª¢I √ù C√ÇU H·ªéI
    # ==============================

    used_questions = {h["question"] for h in main_context_hits}

    filtered_for_suggest = [
        h for h in hits
        if (h["question"] not in used_questions) and (h["score"] >= MIN_SCORE_SUGGEST)
    ]

    suggestions = filtered_for_suggest[:MAX_SUGGEST]

    if suggestions:
        suggestions_text = "\n".join(
            f"- {h['question']}"
            for h in suggestions
        )
    else:
        suggestions_text = "- (Kh√¥ng c√≥ c√¢u g·ª£i √Ω ph√π h·ª£p)"

    # ==============================
    #   G·ªåI LLM (RAG)
    # ==============================

    final_answer = call_finetune_with_context(
        user_query=user_query,
        context=context,
        suggestions_text=suggestions_text
    )

    # N·∫øu primary_doc kh√¥ng c√≥ IMG_KEY n√†o ‚Üí t√πy b·∫°n:
    #  - ho·∫∑c tr·∫£ list r·ªóng,
    #  - ho·∫∑c fallback: extract t·ª´ t·∫•t c·∫£ main_context_hits.
    if img_keys_primary:
        unique_img_keys = sorted(set(img_keys_primary))
    else:
        # Fallback option (n·∫øu mu·ªën)
        collected = []
        for h in main_context_hits:
            collected.extend(extract_img_keys(h["answer"]))
        unique_img_keys = sorted(set(collected))

    return {
        "text": final_answer,
        "img_keys": unique_img_keys,
    }




# ==============================
#   DEMO
# ==============================

if __name__ == "__main__":
    q = 'cho t√¥i bi·∫øt quy tr√¨nh thi·∫øt k·∫ø nh√£n ri√™ng'
    res = answer_with_suggestions(q)

    print("\n===== K·∫æT QU·∫¢ CU·ªêI C√ôNG =====\n")
    print(res["text"])

    print("\nIMG_KEY d√πng ƒë·ªÉ truy xu·∫•t h√¨nh:")
    for k in res["img_keys"]:
        print("-", k)


