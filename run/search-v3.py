import numpy as np
from openai import OpenAI

# ==============================
#       CONFIG
# ==============================

FT_MODEL = "ft:gpt-4o-mini-2024-07-18:personal::CdBoxNIT"   # ƒë·ªïi th√†nh model c·ªßa b·∫°n

MIN_SCORE_MAIN = 0.60       # T·ªëi thi·ªÉu ƒë·ªÉ d√πng l√†m context
MIN_SCORE_SUGGEST = 0.50    # T·ªëi thi·ªÉu ƒë·ªÉ d√πng l√†m g·ª£i √Ω
MAX_SUGGEST = 5             # G·ª£i √Ω t·ªëi ƒëa 5 c√¢u

client = OpenAI(api_key="...")

# ==============================
#       LOAD DATA
# ==============================

data = np.load("tong-hop-data-phong-vat-tu.npz", allow_pickle=True)
EMBS = data["embeddings"]      # (N, d)
QUESTIONS = data["questions"]  # (N,)
ANSWERS = data["answers"]      # (N,)

# ==============================
#       EMBEDDING FUNCTION
# ==============================

def embed_query(text: str):
    resp = client.embeddings.create(
        model="text-embedding-3-small",
        input=[text],
    )
    v = np.array(resp.data[0].embedding, dtype=np.float32)
    v = v / (np.linalg.norm(v) + 1e-8)
    return v

# ==============================
#     NORMALIZE QUERY
# ==============================

def normalize_query(q: str):
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0,
        messages=[
            {
                "role": "system",
                "content": """
B·∫°n l√† Query Normalizer cho tr·ª£ l√Ω V·∫≠t t∆∞ BMC.

Nhi·ªám v·ª•:
1) S·ª≠a l·ªói ch√≠nh t·∫£, chu·∫©n ho√° c√¢u, b·ªè b·ªõt r√°c ng√¥n ng·ªØ (ch·ªØ k√©o d√†i, icon, t·ª´ th·ª´a...) nh∆∞ng kh√¥ng s·ª≠a c√°c c·ª•m t·ª´ gi·ªëng nh∆∞ m√£ v√≠ d·ª• sau ƒë√¢y l√† c√°c m√£: cha240-asmil, cha1000-02logo, b·ªô pet v√†ng, ...
2) B·ªè qua c√°c ph·∫ßn kh√¥ng quan tr·ªçng nh∆∞:
   - ƒë·∫°i t·ª´ nh√¢n x∆∞ng (em, anh, ch·ªã, m√¨nh, t·ª•i em, b√™n em...)
   - l·ªùi ch√†o (hello, xin ch√†o, ch√†o anh/ch·ªã...)
   - l·ªùi c·∫£m ∆°n (c·∫£m ∆°n anh, c·∫£m ∆°n ·∫°, thanks...)
   - t·ª´ c·∫£m th√°n/ƒë·ªám (∆°i, v·ªõi ·∫°, nha, nh√©, ·∫°...)
   - c·ª•m nh∆∞: "cho em h·ªèi", "em mu·ªën h·ªèi", "anh t∆∞ v·∫•n gi√∫p", ...
3) C·ªë g·∫Øng gi·ªØ l·∫°i ƒë√∫ng "√Ω nghi·ªáp v·ª•" m√† ng∆∞·ªùi d√πng ƒëang h·ªèi (n·∫øu c√≥).

ƒê·ªìng th·ªùi, h√£y PH√ÇN LO·∫†I lo·∫°i c√¢u theo 3 nh√≥m:
- "QUESTION": Ng∆∞·ªùi d√πng ƒëang h·ªèi v·ªÅ nghi·ªáp v·ª•, quy tr√¨nh, v·∫≠t t∆∞, k·∫ø ho·∫°ch, t·ªìn kho, nh√† cung c·∫•p, ... (c√≥ th·ªÉ tra trong t√†i li·ªáu).
- "SMALL_TALK": Ng∆∞·ªùi d√πng ch·ªâ ch√†o h·ªèi, c·∫£m ∆°n, khen/ch√™, x√£ giao, n√≥i chuy·ªán vu v∆°, KH√îNG c√≥ √Ω ƒë·ªãnh h·ªèi nghi·ªáp v·ª•.
- "OTHER": C√¢u kh√¥ng r√µ nghƒ©a, spam, ho·∫∑c kh√¥ng thu·ªôc 2 nh√≥m tr√™n.

K·∫æT QU·∫¢ TR·∫¢ V·ªÄ:
- Lu√¥n tr·∫£ v·ªÅ ƒë√∫ng 1 chu·ªói JSON v·ªõi 2 field:
  {
    "normalized_query": "<chu·ªói sau khi chu·∫©n ho√°, n·∫øu kh√¥ng ph·∫£i QUESTION th√¨ ƒë·ªÉ r·ªóng>",
    "intent": "<QUESTION|SMALL_TALK|OTHER>"
  }

Y√äU C·∫¶U:
- Kh√¥ng gi·∫£i th√≠ch, kh√¥ng th√™m ch·ªØ ngo√†i JSON.
"""
            },
            {"role": "user", "content": q}
        ],
    )

    import json

    content = resp.choices[0].message.content.strip()
    try:
        data = json.loads(content)
        # ƒê·∫£m b·∫£o c√≥ ƒë·ªß field
        normalized = data.get("normalized_query", "").strip()
        intent = data.get("intent", "").strip()
        return {
            "normalized_query": normalized,
            "intent": intent
        }
    except Exception:
        # Fallback: coi nh∆∞ c√¢u h·ªèi b√¨nh th∆∞·ªùng
        return {
            "normalized_query": q.strip(),
            "intent": "QUESTION"
        }


# ==============================
#        SEARCH ENGINE
# ==============================

def search(query: str, top_k: int = 10):
    # ·ªû ƒë√¢y query ƒê√É l√† c√¢u ƒë√£ chu·∫©n ho√° (string)
    print("search() received query:", query)

    vq = embed_query(query)         # d√πng th·∫≥ng query string
    sims = EMBS @ vq                # cosine similarity nh∆∞ c≈©

    idx = np.argsort(sims)[::-1][:top_k]

    results = []
    for i in idx:
        results.append({
            "question": str(QUESTIONS[i]),
            "answer": str(ANSWERS[i]),
            "score": float(sims[i]),
        })

    return results

# ==============================
#   CALL FINE-TUNE FOR ANSWER
# ==============================

def call_finetune_with_context(user_query: str, context: str, suggestions_text: str):
    print("user_query: ", user_query)
    system_prompt = (
        "B·∫°n l√† Tr·ª£ l√Ω V·∫≠t t∆∞ BMCVN. Gi·ªçng chuy√™n nghi·ªáp, r√µ r√†ng, "
        "c√≥ bullet khi c·∫ßn. Kh√¥ng b·ªãa th√¥ng tin."
    )

    user_prompt = f"""
NG·ªÆ C·∫¢NH (t√†i li·ªáu n·ªôi b·ªô, c√≥ th·ªÉ kh√¥ng ƒë·∫ßy ƒë·ªß):
\"\"\"{context}\"\"\"

C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG:
\"\"\"{user_query}\"\"\"

Y√äU C·∫¶U:
- Gi·ªØ nguy√™n 100% n·ªôi dung, kh√¥ng ƒë∆∞·ª£c t√≥m t·∫Øt, kh√¥ng ƒë∆∞·ª£c r√∫t g·ªçn, kh√¥ng ƒë∆∞·ª£c thay ƒë·ªïi vƒÉn phong. Tr·∫£ l·ªùi l·∫°i y h·ªát nh∆∞ t√¥i g·ª≠i.
- ∆Øu ti√™n d·ª±a tr√™n NG·ªÆ C·∫¢NH.


G·ª£i √Ω c√¢u h·ªèi ti·∫øp theo m·ªôt c√°ch m·ªÅm m·∫°i, uy·ªÉn chuy·ªÉn, th√¢n thi·ªán v√† b·ªè trong ngo·∫∑c k√©p c√°c c√¢u g·ª£i √Ω ƒë·ªÉ ng∆∞·ªùi d√πng d·ªÖ r√†ng hi·ªÉu v√† h·ªèi ƒë√∫ng c√¢u:
{suggestions_text}
""".strip()

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0.0,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
    )

    return resp.choices[0].message.content.strip()

# ==============================
#   MAIN PIPELINE (FULL FLOW)
# ==============================

def answer_with_suggestions(user_query: str):
    # B1: Chu·∫©n ho√° + ph√¢n lo·∫°i intent b·∫±ng GPT
    norm_result = normalize_query(user_query)
    norm_query = norm_result["normalized_query"]
    intent = norm_result["intent"]

    print("intent:", intent)
    print("norm_query:", norm_query)

    # B2: N·∫øu l√† SMALL_TALK -> tr·∫£ l·ªùi nh·∫π nh√†ng, KH√îNG search, KH√îNG top_k
    if intent == "SMALL_TALK":
        # B·∫°n c√≥ th·ªÉ random 2-3 c√¢u kh√°c nhau cho t·ª± nhi√™n
        return "V√¢ng, em c·∫£m ∆°n anh/ch·ªã. N·∫øu c·∫ßn h·ªó tr·ª£ th√™m g√¨ v·ªÅ v·∫≠t t∆∞, anh/ch·ªã c·ª© nh·∫Øn cho em nh√© ·∫°. üòä"

    # B3: N·∫øu l√† OTHER (l·∫°, kh√¥ng r√µ) -> xin ng∆∞·ªùi d√πng n√≥i r√µ h∆°n, KH√îNG search
    if intent == "OTHER" or not norm_query:
        return (
            "Hi·ªán t·∫°i em ch∆∞a hi·ªÉu r√µ anh/ch·ªã ƒëang mu·ªën h·ªèi v·ªÅ n·ªôi dung n√†o trong ph·∫ßn v·∫≠t t∆∞.\n"
            "Anh/ch·ªã c√≥ th·ªÉ m√¥ t·∫£ c·ª• th·ªÉ h∆°n (v√≠ d·ª•: m√£ chai, th√πng, quy tr√¨nh, t·ªìn kho, k·∫ø ho·∫°ch ƒë·∫∑t h√†ng...) ƒë·ªÉ em tra c·ª©u ch√≠nh x√°c h∆°n ƒë∆∞·ª£c kh√¥ng ·∫°?"
        )

    # B4: Ch·ªâ khi intent == QUESTION m·ªõi ch·∫°y search + top_k
    hits = search(norm_query, top_k=10)

    if not hits:
        return (
            "Em ch∆∞a t√¨m th·∫•y t√†i li·ªáu ph√π h·ª£p v·ªõi c√¢u h·ªèi n√†y trong kho d·ªØ li·ªáu hi·ªán t·∫°i.\n"
            "Anh/ch·ªã m√¥ t·∫£ l·∫°i c·ª• th·ªÉ h∆°n gi√∫p em (v√≠ d·ª•: lo·∫°i v·∫≠t t∆∞, c√¥ng ƒëo·∫°n, ho·∫∑c c√¢u h·ªèi chi ti·∫øt h∆°n) ƒë·ªÉ em h·ªó tr·ª£ t·ªët h∆°n nh√©."
        )

    # --- L·ªçc context ch√≠nh theo threshold ---
    filtered_for_main = [h for h in hits if h["score"] >= MIN_SCORE_MAIN]

    # Kh√¥ng c√≥ doc ƒë·ªß ƒëi·ªÉm -> g·ª£i √Ω top_k (ch·ªâ v√¨ ƒë√¢y l√† QUESTION)
    if not filtered_for_main:
        suggestions_text = "\n".join(
            f"- {h['question']} (score={h['score']:.2f})"
            for h in hits
        )
        return (
            "Em ch∆∞a t√¨m ƒë∆∞·ª£c t√†i li·ªáu n√†o th·∫≠t s·ª± kh·ªõp 100% v·ªõi c√¢u h·ªèi.\n"
            "Tuy nhi√™n c√≥ m·ªôt s·ªë n·ªôi dung g·∫ßn v·ªõi √Ω anh/ch·ªã, anh/ch·ªã tham kh·∫£o th·ª≠ xem c√≥ ƒë√∫ng c√°i m√¨nh c·∫ßn kh√¥ng ·∫°:\n\n"
            f"{suggestions_text}\n\n"
            "üëâ N·∫øu ch∆∞a ƒë√∫ng, anh/ch·ªã m√¥ t·∫£ r√µ h∆°n (th√™m m√£ v·∫≠t t∆∞, t√™n chai/th√πng, lo·∫°i quy tr√¨nh...) ƒë·ªÉ em t√¨m l·∫°i cho ch√≠nh x√°c h∆°n nh√©."
        )

    # C√≤n l·∫°i: c√≥ context ch√≠nh -> x·ª≠ l√Ω nh∆∞ c≈©
    main_hit = filtered_for_main[0]
    context = main_hit["answer"]

    filtered_for_suggest = [
        h for h in hits
        if h["question"] != main_hit["question"] and h["score"] >= MIN_SCORE_SUGGEST
    ]

    suggestions = filtered_for_suggest[:MAX_SUGGEST]

    if suggestions:
        suggestions_text = "\n".join(
            f"- {h['question']} (score={h['score']:.2f})"
            for h in suggestions
        )
    else:
        suggestions_text = "- (Kh√¥ng c√≥ c√¢u g·ª£i √Ω ph√π h·ª£p)"

    final_answer = call_finetune_with_context(
        user_query=user_query,
        context=context,
        suggestions_text=suggestions_text
    )

    return final_answer


# ==============================
#   DEMO
# ==============================

if __name__ == "__main__":
    q = "hay qu√°"
    ans = answer_with_suggestions(q)
    print("\n===== K·∫æT QU·∫¢ CU·ªêI C√ôNG =====\n")
    print(ans)
